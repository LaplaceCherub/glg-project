{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yinghu/Documents/GitHub/fourthBrain/glg-project/week_11_models\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_dataset = pd.read_csv('/Users/yinghu/Documents/GitHub/fourthBrain/glg-project/datasets/ner_dataset.csv', \n",
    "    encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278201</th>\n",
       "      <td>NaN</td>\n",
       "      <td>claimed</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127775</th>\n",
       "      <td>NaN</td>\n",
       "      <td>70</td>\n",
       "      <td>CD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799712</th>\n",
       "      <td>NaN</td>\n",
       "      <td>roadside</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565637</th>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033110</th>\n",
       "      <td>NaN</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698525</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Cameron</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-per</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529651</th>\n",
       "      <td>NaN</td>\n",
       "      <td>say</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449446</th>\n",
       "      <td>NaN</td>\n",
       "      <td>seizing</td>\n",
       "      <td>VBG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446377</th>\n",
       "      <td>Sentence: 20400</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-per</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598148</th>\n",
       "      <td>NaN</td>\n",
       "      <td>an</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sentence #      Word  POS    Tag\n",
       "278201               NaN   claimed  VBD      O\n",
       "127775               NaN        70   CD      O\n",
       "799712               NaN  roadside   NN      O\n",
       "565637               NaN         a   DT      O\n",
       "1033110              NaN        to   TO      O\n",
       "698525               NaN   Cameron  NNP  B-per\n",
       "529651               NaN       say  VBP      O\n",
       "449446               NaN   seizing  VBG      O\n",
       "446377   Sentence: 20400       Mr.  NNP  B-per\n",
       "598148               NaN        an   DT      O"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_dataset.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the missing `Sentence #`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_dataset['Sentence #'] = ner_dataset['Sentence #'].str.replace('Sentence:', '').astype(int)\n",
    "ner_dataset = ner_dataset.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence #     int64\n",
       "Word          object\n",
       "POS           object\n",
       "Tag           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare `reduced_df` for feature extraction of `sentences_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = extended_df[['Sentence #', 'Word', 'Tag', 'StopWord', 'Non-Punctuation']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In `Sentence #` column, we replace `NaN` by the sentence number the word belongs to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence_nums = reduced_df['Sentence #'].copy()\n",
    "#sentence_nums = sentence_nums.apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "#sentence_nums = sentence_nums.cumsum()\n",
    "#reduced_df['Sentence num'] = sentence_nums\n",
    "#reduced_df = reduced_df.drop(columns=['Sentence #'])\n",
    "\n",
    "def add_sentence_num(df):\n",
    "    df['Sentence #'] = df['Sentence #'].str.replace('Sentence: ', '')\n",
    "    df['Sentence #'].fillna(method='ffill', inplace=True)\n",
    "    df['Sentence #'] = df['Sentence #'].astype('int64')\n",
    "    return df \n",
    "\n",
    "reduced_df = add_sentence_num(reduced_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df_org = reduced_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Change values in `Word` column from `str` to `[str]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_col = reduced_df.copy()['Word'].apply(lambda x: [x])  # pd.Series\n",
    "reduced_df = reduced_df.assign(Word=word_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "      <th>StopWord</th>\n",
       "      <th>Non-Punctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[Thousands]</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[of]</td>\n",
       "      <td>O</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[demonstrators]</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[have]</td>\n",
       "      <td>O</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[marched]</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>47959</td>\n",
       "      <td>[they]</td>\n",
       "      <td>O</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>47959</td>\n",
       "      <td>[responded]</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>47959</td>\n",
       "      <td>[to]</td>\n",
       "      <td>O</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>47959</td>\n",
       "      <td>[the]</td>\n",
       "      <td>O</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>47959</td>\n",
       "      <td>[attack]</td>\n",
       "      <td>O</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sentence #             Word Tag  StopWord  Non-Punctuation\n",
       "0                 1      [Thousands]   O     False             True\n",
       "1                 1             [of]   O      True             True\n",
       "2                 1  [demonstrators]   O     False             True\n",
       "3                 1           [have]   O      True             True\n",
       "4                 1        [marched]   O     False             True\n",
       "...             ...              ...  ..       ...              ...\n",
       "1048570       47959           [they]   O      True             True\n",
       "1048571       47959      [responded]   O     False             True\n",
       "1048572       47959             [to]   O      True             True\n",
       "1048573       47959            [the]   O      True             True\n",
       "1048574       47959         [attack]   O     False             True\n",
       "\n",
       "[1048575 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Add `Content` column to `setentences_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_temp = reduced_df[['Sentence #', 'Word']].copy().groupby(['Sentence #']).sum()\n",
    "df_grouped_temp = df_grouped_temp.reset_index()\n",
    "\n",
    "content = df_grouped_temp.copy()['Word']\n",
    "sentences_df = sentences_df.assign(Content=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sentence Length</th>\n",
       "      <th>Sentence#</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>[Families, of, soldiers, killed, in, the, conf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>[They, marched, from, the, Houses, of, Parliam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>[Police, put, the, number, of, marchers, at, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>[The, protest, comes, on, the, eve, of, the, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47954</th>\n",
       "      <td>47954</td>\n",
       "      <td>20</td>\n",
       "      <td>47955</td>\n",
       "      <td>[Indian, border, security, forces, are, accusi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47955</th>\n",
       "      <td>47955</td>\n",
       "      <td>24</td>\n",
       "      <td>47956</td>\n",
       "      <td>[Indian, officials, said, no, one, was, injure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47956</th>\n",
       "      <td>47956</td>\n",
       "      <td>11</td>\n",
       "      <td>47957</td>\n",
       "      <td>[Two, more, landed, in, fields, belonging, to,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47957</th>\n",
       "      <td>47957</td>\n",
       "      <td>11</td>\n",
       "      <td>47958</td>\n",
       "      <td>[They, say, not, all, of, the, rockets, explod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47958</th>\n",
       "      <td>47958</td>\n",
       "      <td>9</td>\n",
       "      <td>47959</td>\n",
       "      <td>[Indian, forces, said, they, responded, to, th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47959 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Sentence Length  Sentence#  \\\n",
       "0               0               24          1   \n",
       "1               1               30          2   \n",
       "2               2               14          3   \n",
       "3               3               15          4   \n",
       "4               4               25          5   \n",
       "...           ...              ...        ...   \n",
       "47954       47954               20      47955   \n",
       "47955       47955               24      47956   \n",
       "47956       47956               11      47957   \n",
       "47957       47957               11      47958   \n",
       "47958       47958                9      47959   \n",
       "\n",
       "                                                 Content  \n",
       "0      [Thousands, of, demonstrators, have, marched, ...  \n",
       "1      [Families, of, soldiers, killed, in, the, conf...  \n",
       "2      [They, marched, from, the, Houses, of, Parliam...  \n",
       "3      [Police, put, the, number, of, marchers, at, 1...  \n",
       "4      [The, protest, comes, on, the, eve, of, the, a...  \n",
       "...                                                  ...  \n",
       "47954  [Indian, border, security, forces, are, accusi...  \n",
       "47955  [Indian, officials, said, no, one, was, injure...  \n",
       "47956  [Two, more, landed, in, fields, belonging, to,...  \n",
       "47957  [They, say, not, all, of, the, rockets, explod...  \n",
       "47958  [Indian, forces, said, they, responded, to, th...  \n",
       "\n",
       "[47959 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add `Tagged Words` to `sentences_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df['Tagged Word'] = reduced_df.loc[:, 'Word'] # create a column 'Tagged word'\n",
    "reduced_df.loc[reduced_df['Tag']=='O', 'Tagged Word'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_temp = reduced_df[['Sentence #', 'Tagged Word']].copy().groupby(\"Sentence #\").sum()\n",
    "df_grouped_temp = df_grouped_temp.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df['Tagged Words'] = df_grouped_temp['Tagged Word']\n",
    "sentences_df.loc[sentences_df[\"Tagged Words\"]==0, 'Tagged Words'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add `Shortened Sentences` to `sentences_df`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentences with stop words revmoved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df_org_temp = reduced_df_org.copy()\n",
    "reduced_df_org_temp['Non StopWord'] = reduced_df_org_temp.loc[:, 'Word']\n",
    "reduced_df_org_temp.loc[reduced_df_org_temp['StopWord']==True, 'Non StopWord'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_stop = reduced_df_org_temp.groupby('Sentence #')['Non StopWord'].apply(lambda x:x.str.cat(sep=' '))\n",
    "non_stop = non_stop.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df['Shortened Sentences'] = non_stop['Non StopWord']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sentence Length</th>\n",
       "      <th>Sentence#</th>\n",
       "      <th>Content</th>\n",
       "      <th>Tagged Words</th>\n",
       "      <th>Shortened Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19519</th>\n",
       "      <td>19519</td>\n",
       "      <td>31</td>\n",
       "      <td>19520</td>\n",
       "      <td>[The, telegram, says, Pope, Benedict, is, also...</td>\n",
       "      <td>[Pope, Benedict]</td>\n",
       "      <td>telegram says Pope Benedict   praying   rescu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39431</th>\n",
       "      <td>39431</td>\n",
       "      <td>25</td>\n",
       "      <td>39432</td>\n",
       "      <td>[Clinton, told, reporters, at, the, United, Na...</td>\n",
       "      <td>[Clinton, United, Nations, Wednesday, U.S., Bu...</td>\n",
       "      <td>Clinton told reporters   United Nations Wednes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>591</td>\n",
       "      <td>18</td>\n",
       "      <td>592</td>\n",
       "      <td>[The, African, United, Democratic, Party, trie...</td>\n",
       "      <td>[African, United, Democratic, Party, 2006]</td>\n",
       "      <td>African United Democratic Party tried unsucce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>2198</td>\n",
       "      <td>18</td>\n",
       "      <td>2199</td>\n",
       "      <td>[Japanese, Chief, Cabinet, Secretary, Hiroyuki...</td>\n",
       "      <td>[Japanese, Secretary, Hiroyuki, Hosoda, Tokyo,...</td>\n",
       "      <td>Japanese Chief Cabinet Secretary Hiroyuki Hoso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39809</th>\n",
       "      <td>39809</td>\n",
       "      <td>36</td>\n",
       "      <td>39810</td>\n",
       "      <td>[Spokesman, Aka, Bian, Tanoh, blamed, the, out...</td>\n",
       "      <td>[Aka, Bian, Tanoh, 2002]</td>\n",
       "      <td>Spokesman Aka Bian Tanoh blamed  outbreak   la...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Sentence Length  Sentence#  \\\n",
       "19519       19519               31      19520   \n",
       "39431       39431               25      39432   \n",
       "591           591               18        592   \n",
       "2198         2198               18       2199   \n",
       "39809       39809               36      39810   \n",
       "\n",
       "                                                 Content  \\\n",
       "19519  [The, telegram, says, Pope, Benedict, is, also...   \n",
       "39431  [Clinton, told, reporters, at, the, United, Na...   \n",
       "591    [The, African, United, Democratic, Party, trie...   \n",
       "2198   [Japanese, Chief, Cabinet, Secretary, Hiroyuki...   \n",
       "39809  [Spokesman, Aka, Bian, Tanoh, blamed, the, out...   \n",
       "\n",
       "                                            Tagged Words  \\\n",
       "19519                                   [Pope, Benedict]   \n",
       "39431  [Clinton, United, Nations, Wednesday, U.S., Bu...   \n",
       "591           [African, United, Democratic, Party, 2006]   \n",
       "2198   [Japanese, Secretary, Hiroyuki, Hosoda, Tokyo,...   \n",
       "39809                           [Aka, Bian, Tanoh, 2002]   \n",
       "\n",
       "                                     Shortened Sentences  \n",
       "19519   telegram says Pope Benedict   praying   rescu...  \n",
       "39431  Clinton told reporters   United Nations Wednes...  \n",
       "591     African United Democratic Party tried unsucce...  \n",
       "2198   Japanese Chief Cabinet Secretary Hiroyuki Hoso...  \n",
       "39809  Spokesman Aka Bian Tanoh blamed  outbreak   la...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save `sentences_df` as csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduced_df.to_csv('reduced_df.csv')\n",
    "sentences_df.to_csv('sentences_v1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download the full model \n",
    "# import gensim.downloader as api \n",
    "# wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Mean with bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use bag of words to encode shortened sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47959, 27706)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "shortened_sentences_bow = vectorizer.fit_transform(sentences_df['Shortened Sentences'])\n",
    "print(shortened_sentences_bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit and evaluate K-Mean model (true labels are unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_clusters = 3: Silhouette Coefficient: 0.010068379210426638\n",
      "n_clusters = 4: Silhouette Coefficient: 0.011919093397266331\n",
      "n_clusters = 5: Silhouette Coefficient: 0.013364127035644687\n",
      "n_clusters = 6: Silhouette Coefficient: 0.012966342284531843\n",
      "n_clusters = 7: Silhouette Coefficient: 0.032791462910272025\n",
      "n_clusters = 8: Silhouette Coefficient: 0.028764928833763415\n",
      "n_clusters = 9: Silhouette Coefficient: 0.014308675488758934\n",
      "n_clusters = 10: Silhouette Coefficient: 0.013340042737080206\n",
      "n_clusters = 11: Silhouette Coefficient: 0.011698526249829278\n",
      "n_clusters = 12: Silhouette Coefficient: 0.012158417380356865\n",
      "n_clusters = 13: Silhouette Coefficient: 0.013536046907808304\n",
      "n_clusters = 14: Silhouette Coefficient: 0.009958963172837274\n"
     ]
    }
   ],
   "source": [
    "for n_cluster in range(3,15):\n",
    "    kmeans_model = KMeans(n_clusters=n_cluster, random_state=1).fit(shortened_sentences_bow)\n",
    "    labels = kmeans_model.labels_\n",
    "\n",
    "    # print(f'Calinski-Harabasz Index: {calinski_harabasz_score(sample_data, labels)}')\n",
    "    # print(f'Davies-Bouldin Index: {davies_bouldin_score(sample_data, labels)}')\n",
    "    print(f'n_clusters = {n_cluster}: Silhouette Coefficient: {silhouette_score(shortened_sentences_bow, labels)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Mean with TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "shortened_sentences_tfidf = vectorizer_tfidf.fit_transform(sentences_df['Shortened Sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47959, 27706)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortened_sentences_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_clusters = 3: Silhouette Coefficient: 0.001727999414975458\n",
      "n_clusters = 4: Silhouette Coefficient: 0.0022900932816321737\n",
      "n_clusters = 5: Silhouette Coefficient: 0.0025437715733283026\n",
      "n_clusters = 6: Silhouette Coefficient: 0.003272915172624837\n",
      "n_clusters = 7: Silhouette Coefficient: 0.003644550697878073\n",
      "n_clusters = 8: Silhouette Coefficient: 0.003361256118098299\n",
      "n_clusters = 9: Silhouette Coefficient: 0.003750177526948939\n",
      "n_clusters = 10: Silhouette Coefficient: 0.004631039850651867\n",
      "n_clusters = 11: Silhouette Coefficient: 0.004013381132652468\n",
      "n_clusters = 12: Silhouette Coefficient: 0.0042527648207261876\n",
      "n_clusters = 13: Silhouette Coefficient: 0.005017270655819071\n",
      "n_clusters = 14: Silhouette Coefficient: 0.005285629825189062\n"
     ]
    }
   ],
   "source": [
    "for n_cluster in range(3,15):\n",
    "    kmeans_model = KMeans(n_clusters=n_cluster, random_state=1).fit(shortened_sentences_tfidf)\n",
    "    labels = kmeans_model.labels_\n",
    "\n",
    "    # print(f'Calinski-Harabasz Index: {calinski_harabasz_score(sample_data, labels)}')\n",
    "    # print(f'Davies-Bouldin Index: {davies_bouldin_score(sample_data, labels)}')\n",
    "    print(f'n_clusters = {n_cluster}: Silhouette Coefficient: {silhouette_score(shortened_sentences_tfidf, labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('glg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a089b623389f25476dadc88e27c19e01bed25fe38415d8d9feae642f6af10d88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
