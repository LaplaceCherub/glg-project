# üöÄ GLG project


## ü§ù A match made in machine learning heaven: linking every request to the best expert
### üßë‚Äçü§ù‚Äçüßë By [Cris Fortes](https://www.linkedin.com/in/crisfortes/), [Ying Hu](https://www.linkedin.com/in/ying-hu-math/) and [Cody McCormack](https://www.linkedin.com/in/codymccormack/)

---

**Context:** Cris, Ying and Cody are students of [FourthBrain's](https://fourthbrain.ai/) [Machine Learning Engineer course](https://fourthbrain.ai/courses/machine-learning-engineer/), cohort 9 (August-December 2022). This repository (repo) is part of our capstone project, a required deliverable from our curriculum. For that we've chosen to work on the GLG project.

---

**The problem**: 

GLG's business largely revolves around matching clients, requesting insights on a specific topic, with an expert on that topic from their large database so that they can meet by phone, video or in person. Visually: 

[INSERT BELOW PICTURE OF PROCESS FLOW]

Since GLG receives 100s of these requests per day, how can they leverage machine learning to semi-automate the matching process at scale? 

---

**The solution**:

Natural Language Processing (NLP), consisting of three steps:

- Step 1:  Named-Entity Recognition (NER)
Possible libraries: spaCy, The Natural Language Toolkit (NLTK), TensorFlow, Keras

- Step 2: Hierarchical clustering
Under consideration: decision tree, K-means clustering, Latent Dirichlet allocation (LDA)

- *Step 3: build a recommendation system to suggest the highest matching expert(s) for each request but that is outside the scope of this project

---

**Illustrative and simplified example**: 

[INSERT BELOW PICTURE OF THREE AFOREMENTIONED STEPS INCLUDING INPUT/MODEL/OUTPUT SEQUENCE]

Acronyms: NLP (Natural Language Processing), NER (Named-Entity Recognition), HC (Hierarchical Clustering), 
DJ (Disc Jockey), GLG (Gerson Lehrman Group). * Step 3 is outside the scope of this project

---

**Data:**

Did exploratory data analysis (EDA) on two datasets from Kaggle:

Annotated Corpus for Named Entity Recognition | Kaggle 

[INSERT BELOW PICTURE WITH EXAMPLES OF PERFORMED EDA]

---

**Next step:** train our model using this other 2.7-million news articles dataset:

All the News 2.0 - Components

[PLACEHOLDER: Establish baseline model through AutoML or a pre-trained model + Document performance report in markdown]

---

**Data and model iteration:** [PLACEHOLDER]

[PLACEHOLDER: Document performance, interpretation, and learnings in markdown]

[PLACEHOLDER:Document limitations of your model / data / ML pipeline]

[PLACEHOLDER: Restructure GitHub into scripts / modules / submodules]

[PLACEHOLDER: Ensure that instructors can easily follow your README.md instructions to deploy your demo locally and in the cloud.]

---

**MLE Stack:** [PLACEHOLDER]

[Exploratory Data Analysis & Wrangling, Experimentation, Data Engineering Pipeline, Machine Learning Pipeline, Deployment Pipeline]

[Maybe consider: Feature Store, Metadata store, Model registry, Model serving, Model Monitoring]

---

**Conclusions:** [PLACEHOLDER]

---

**Future Work:** [PLACEHOLDER]

---

**Authors and acknowledgment:** [PLACEHOLDER]

---

**License:** [PLACEHOLDER]
