{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modelling \n",
    "\n",
    "In this notebook, we apply topic modelling algorithms to our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import nltk\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim import models, matutils\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /Users/yinghu/nltk_data...\n",
      "[nltk_data] Downloading package wordnet to /Users/yinghu/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4') #  Open Multilingual Wordnet\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data done from the previous work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yinghu/Documents/GitHub/fourthBrain/glg-project/week_8_models'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_df = pd.read_csv('../datasets/extended_df.csv')\n",
    "sentences_df = pd.read_csv('../datasets/sentences_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>WordLength</th>\n",
       "      <th>Capital</th>\n",
       "      <th>Non-Punctuation</th>\n",
       "      <th>StopWord</th>\n",
       "      <th>IsNER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Sentence #           Word  POS Tag  WordLength  Capital  \\\n",
       "0           0  Sentence: 1      Thousands  NNS   O           9     True   \n",
       "1           1          NaN             of   IN   O           2    False   \n",
       "2           2          NaN  demonstrators  NNS   O          13    False   \n",
       "3           3          NaN           have  VBP   O           4    False   \n",
       "4           4          NaN        marched  VBN   O           7    False   \n",
       "\n",
       "   Non-Punctuation  StopWord  IsNER  \n",
       "0             True     False      0  \n",
       "1             True      True      0  \n",
       "2             True     False      0  \n",
       "3             True      True      0  \n",
       "4             True     False      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sentence Length</th>\n",
       "      <th>Sentence#</th>\n",
       "      <th>Content</th>\n",
       "      <th>Tagged Words</th>\n",
       "      <th>Shortened Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>['Thousands', 'of', 'demonstrators', 'have', '...</td>\n",
       "      <td>['London', 'Iraq', 'British']</td>\n",
       "      <td>Thousands  demonstrators  marched  London  pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>['Families', 'of', 'soldiers', 'killed', 'in',...</td>\n",
       "      <td>['Bush']</td>\n",
       "      <td>Families  soldiers killed   conflict joined  p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>['They', 'marched', 'from', 'the', 'Houses', '...</td>\n",
       "      <td>['Hyde', 'Park']</td>\n",
       "      <td>marched   Houses  Parliament   rally  Hyde Pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>['Police', 'put', 'the', 'number', 'of', 'marc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police   number  marchers  10,000  organizers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>['The', 'protest', 'comes', 'on', 'the', 'eve'...</td>\n",
       "      <td>['Britain', 'Labor', 'Party', 'English', 'Brig...</td>\n",
       "      <td>protest comes   eve   annual conference  Brit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Sentence Length  Sentence#  \\\n",
       "0           0               24          1   \n",
       "1           1               30          2   \n",
       "2           2               14          3   \n",
       "3           3               15          4   \n",
       "4           4               25          5   \n",
       "\n",
       "                                             Content  \\\n",
       "0  ['Thousands', 'of', 'demonstrators', 'have', '...   \n",
       "1  ['Families', 'of', 'soldiers', 'killed', 'in',...   \n",
       "2  ['They', 'marched', 'from', 'the', 'Houses', '...   \n",
       "3  ['Police', 'put', 'the', 'number', 'of', 'marc...   \n",
       "4  ['The', 'protest', 'comes', 'on', 'the', 'eve'...   \n",
       "\n",
       "                                        Tagged Words  \\\n",
       "0                      ['London', 'Iraq', 'British']   \n",
       "1                                           ['Bush']   \n",
       "2                                   ['Hyde', 'Park']   \n",
       "3                                                NaN   \n",
       "4  ['Britain', 'Labor', 'Party', 'English', 'Brig...   \n",
       "\n",
       "                                 Shortened Sentences  \n",
       "0  Thousands  demonstrators  marched  London  pro...  \n",
       "1  Families  soldiers killed   conflict joined  p...  \n",
       "2   marched   Houses  Parliament   rally  Hyde Pa...  \n",
       "3  Police   number  marchers  10,000  organizers ...  \n",
       "4   protest comes   eve   annual conference  Brit...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorization and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8411    NaN\n",
       "Name: Shortened Sentences, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortened_sent = sentences_df['Shortened Sentences']\n",
    "shortened_sent[shortened_sent.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop sentence 8411"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortened_sent.drop(8411, inplace=True)\n",
    "shortened_sent.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the `LemmaTokenizer` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer:\n",
    "    def __init__(self) -> None:\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    \n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in doc.lower().split(' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47958,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortened_sent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vectorizer = CountVectorizer(tokenizer=LemmaTokenizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortened_sent_bow = bow_vectorizer.fit_transform(shortened_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47958, 28760)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortened_sent_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = {idx: word for word, idx in bow_vectorizer.vocabulary_.items()}\n",
    "corpus = shortened_sent_bow.transpose()\n",
    "corpus = matutils.Sparse2Corpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28760, 47958)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lad = models.LdaModel(corpus, num_topics=10, id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.166*\"charge\" + 0.033*\"destroyed\" + 0.029*\"denies\" + 0.014*\"highly\" + 0.008*\"bombed\" + 0.007*\"warplane\" + 0.005*\"classified\" + 0.004*\"garang\" + 0.003*\"hectare\" + 0.002*\"zuma\"'),\n",
       " (1,\n",
       "  '0.329*\"\" + 0.046*\".\" + 0.041*\",\" + 0.024*\"president\" + 0.019*\"minister\" + 0.017*\"mr.\" + 0.009*\"prime\" + 0.007*\"leader\" + 0.006*\"bush\" + 0.006*\"talk\"'),\n",
       " (2,\n",
       "  '0.467*\"\" + 0.051*\".\" + 0.036*\",\" + 0.006*\"said\" + 0.004*\"year\" + 0.004*\"say\" + 0.004*\"official\" + 0.003*\"government\" + 0.003*\"country\" + 0.003*\"people\"'),\n",
       " (3,\n",
       "  '0.048*\"pakistan\" + 0.039*\"deputy\" + 0.032*\"injury\" + 0.031*\"damage\" + 0.027*\"tribal\" + 0.027*\"paul\" + 0.021*\"jet\" + 0.018*\"region\" + 0.017*\"waziristan\" + 0.016*\"northwestern\"'),\n",
       " (4,\n",
       "  '0.038*\"demonstration\" + 0.036*\"olympic\" + 0.022*\"consumer\" + 0.021*\"index\" + 0.017*\"staged\" + 0.015*\"prominent\" + 0.015*\"confidence\" + 0.014*\"illegally\" + 0.013*\"winter\" + 0.011*\"slightly\"'),\n",
       " (5,\n",
       "  '0.273*\"\" + 0.047*\",\" + 0.040*\".\" + 0.019*\"election\" + 0.015*\"party\" + 0.012*\")\" + 0.012*\"(\" + 0.009*\"president\" + 0.008*\"mr.\" + 0.007*\"opposition\"'),\n",
       " (6,\n",
       "  '0.405*\"\" + 0.050*\".\" + 0.029*\",\" + 0.009*\"killed\" + 0.007*\"official\" + 0.007*\"u.s.\" + 0.006*\"attack\" + 0.006*\"military\" + 0.006*\"say\" + 0.006*\"said\"'),\n",
       " (7,\n",
       "  '0.044*\"interim\" + 0.026*\"urging\" + 0.025*\"upcoming\" + 0.011*\"allawi\" + 0.008*\"silence\" + 0.005*\"iyad\" + 0.003*\"observed\" + 0.003*\"latortue\" + 0.002*\"gerard\" + 0.002*\"selection\"'),\n",
       " (8,\n",
       "  '0.034*\"egypt\" + 0.027*\"voa\" + 0.019*\"egyptian\" + 0.019*\"point\" + 0.019*\"muslim\" + 0.018*\"mosque\" + 0.015*\"fell\" + 0.015*\"\" + 0.014*\"christian\" + 0.014*\"airport\"'),\n",
       " (9,\n",
       "  '0.338*\"\" + 0.043*\".\" + 0.033*\"\"\" + 0.018*\",\" + 0.018*\"united\" + 0.017*\"state\" + 0.014*\"iran\" + 0.010*\"say\" + 0.010*\"nuclear\" + 0.009*\"u.s.\"')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lad.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('glg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a089b623389f25476dadc88e27c19e01bed25fe38415d8d9feae642f6af10d88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
